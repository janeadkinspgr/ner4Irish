{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a9c9610bf12f43a5b5e4fc926b29c85c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1c09a6735f0748f994f841eb5c08758d",
              "IPY_MODEL_17cf5a0437964d0a9bb7af6fc7ff2971",
              "IPY_MODEL_63425cf1cc914310acf20578ea5b9d36"
            ],
            "layout": "IPY_MODEL_182b2b6086404a9ab8bfa517cc27c39f"
          }
        },
        "1c09a6735f0748f994f841eb5c08758d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2885ef1b21e44141bb61d879d1b03aa9",
            "placeholder": "​",
            "style": "IPY_MODEL_ddb30a69915c47e0b83b980a5dc8e404",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "17cf5a0437964d0a9bb7af6fc7ff2971": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ff6f0c71ad8042488aba46eb5be8a3d7",
            "max": 439219446,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_16fe093696d842f4a49a36d44e7efb90",
            "value": 439219446
          }
        },
        "63425cf1cc914310acf20578ea5b9d36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a54614ffad0e4ce0be11c8cf52f0d433",
            "placeholder": "​",
            "style": "IPY_MODEL_858f408c8baf4c68aa64ddee71d4ab15",
            "value": " 439M/439M [00:08&lt;00:00, 56.0MB/s]"
          }
        },
        "182b2b6086404a9ab8bfa517cc27c39f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2885ef1b21e44141bb61d879d1b03aa9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ddb30a69915c47e0b83b980a5dc8e404": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ff6f0c71ad8042488aba46eb5be8a3d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "16fe093696d842f4a49a36d44e7efb90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a54614ffad0e4ce0be11c8cf52f0d433": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "858f408c8baf4c68aa64ddee71d4ab15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install tokenizers\n",
        "!pip install seqeval\n",
        "!pip install pytorch-crf\n",
        "from torchcrf import CRF\n",
        "import torch\n",
        "from transformers import BertModel, AutoModelForTokenClassification, AutoTokenizer, Trainer, TrainingArguments, AdamW, BertConfig, get_linear_schedule_with_warmup, get_constant_schedule_with_warmup, get_cosine_with_hard_restarts_schedule_with_warmup\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from seqeval.metrics import f1_score, accuracy_score\n",
        "from tqdm import tqdm, trange\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "log_soft = F.log_softmax"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K2KZs7yKit48",
        "outputId": "146bb552-2eec-4eeb-a8a4-3d293e50f2de"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.48.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.28.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.11/dist-packages (0.21.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers) (0.28.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (3.17.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers) (2025.1.31)\n",
            "Requirement already satisfied: seqeval in /usr/local/lib/python3.11/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from seqeval) (1.26.4)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.11/dist-packages (from seqeval) (1.6.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.5.0)\n",
            "Requirement already satisfied: pytorch-crf in /usr/local/lib/python3.11/dist-packages (0.7.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LEN = 256\n",
        "bs = 32"
      ],
      "metadata": {
        "id": "XXZ95tPAjw9p"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_conll_file(file_path):\n",
        "    data = []\n",
        "    current_sentence = []\n",
        "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
        "        for line in file:\n",
        "            line = line.strip()\n",
        "            if line.startswith('-DOCSTART-'):\n",
        "                continue\n",
        "            if line:\n",
        "                parts = line.split()\n",
        "                word = parts[0]\n",
        "                ner_label = parts[-1]\n",
        "                current_sentence.append((word, ner_label))\n",
        "            else:\n",
        "                if current_sentence:\n",
        "                    data.append(current_sentence)\n",
        "                    current_sentence = []\n",
        "    if current_sentence:\n",
        "        data.append(current_sentence)\n",
        "    return data"
      ],
      "metadata": {
        "id": "1376dTkTiwei"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = read_conll_file('/content/train_final.conll')\n",
        "val_data = read_conll_file('/content/NER_Irish_validation.conll')\n",
        "test_data = read_conll_file('/content/NER_Irish_test.conll')"
      ],
      "metadata": {
        "id": "NiANHrW6i08t"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Finding instances of multi-word named entities\n",
        "\n",
        "def findMWE(sentence):\n",
        "    tags = [tag for _, tag in sentence]  # Extract only the tags\n",
        "\n",
        "    # Condition 1: Sentence must contain at least one 'I-' tag\n",
        "    if not any(tag.startswith('I-') for tag in tags):\n",
        "        return False\n",
        "\n",
        "    # Condition 2: Ensure all 'B-' tags are followed by an 'I-' tag\n",
        "    prev_tag = None\n",
        "    for tag in tags:\n",
        "        if tag.startswith('B-'):\n",
        "            prev_tag = tag  # Store current 'B-' tag\n",
        "        elif tag.startswith('I-'):\n",
        "            if prev_tag and prev_tag[2:] == tag[2:]:  # Matching entity type\n",
        "                prev_tag = None  # Valid sequence, reset\n",
        "\n",
        "    # If there's still a lingering 'B-' tag, it means it wasn't followed correctly\n",
        "    return prev_tag is None\n",
        "\n",
        "\n",
        "mwe_test_data = [sentence for sentence in test_data if findMWE(sentence)]\n",
        "print(len(mwe_test_data))\n",
        "print(mwe_test_data[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E6u5HC5Gr1-4",
        "outputId": "5156a5aa-2d4d-49c7-aae8-54a0e6dcea28"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "89\n",
            "[[('Mar', 'O'), ('a', 'O'), ('tchítear', 'O'), ('do', 'O'), ('Sheosamh', 'B-PER'), ('Mac', 'I-PER'), ('Grianna', 'I-PER'), ('é', 'O'), ('caithfidh', 'O'), ('an', 'O'), ('t-ealaíontóir', 'O'), ('an', 'O'), ('solas', 'O'), ('a', 'O'), ('thabhairt', 'O'), ('don', 'O'), ('saol', 'O'), ('agus', 'O'), ('diúltú', 'O'), ('do', 'O'), ('chathú', 'O'), ('sin', 'O'), ('na', 'O'), ('truaillíochta', 'O'), ('a', 'O'), ('chuireann', 'O'), ('an', 'O'), ('saol', 'O'), ('ina', 'O'), ('chosán', 'O'), ('.', 'O')], [('Grianghraif', 'O'), ('le', 'O'), ('Maidhc', 'B-PER'), ('Ó', 'I-PER'), ('Seachnasaí', 'I-PER'), ('.', 'O')], [('Tagann', 'O'), ('a', 'O'), ('ráiteas', 'O'), ('tar', 'O'), ('éis', 'O'), ('don', 'O'), ('chomhlacht', 'O'), ('a', 'O'), ('rá', 'O'), ('le', 'O'), ('hoibrithe', 'O'), ('an', 'O'), ('iarnróid', 'O'), ('mí', 'O'), ('ó', 'O'), ('shin', 'O'), ('go', 'O'), ('raibh', 'O'), ('sí', 'O'), ('le', 'O'), ('dúnadh', 'O'), (':', 'O'), (\"'Chuamar\", 'O'), ('ag', 'O'), ('cruinniú', 'O'), ('i', 'O'), ('mBaile', 'B-LOC'), ('Átha', 'I-LOC'), ('an', 'I-LOC'), ('Rí', 'I-LOC'), ('agus', 'O'), ('dúirt', 'O'), ('an', 'O'), ('bhainistíocht', 'O'), ('linn', 'O'), ('ansin', 'O'), ('go', 'O'), ('raibh', 'O'), ('deireadh', 'O'), ('leis', 'O'), ('an', 'O'), ('tseirbhís', 'O'), ('lasta', 'O'), ('agus', 'O'), ('go', 'O'), ('raibh', 'O'), ('baol', 'O'), ('ann', 'O'), ('dár', 'O'), ('bpostanna', 'O'), (',', 'O'), (\"'\", 'O'), ('a', 'O'), ('deir', 'O'), ('Pat', 'B-PER'), ('McDonagh', 'I-PER'), (',', 'O'), ('oibrí', 'O'), ('ar', 'O'), ('an', 'O'), ('líne', 'O'), ('le', 'O'), ('25', 'O'), ('bliain', 'O'), ('anuas', 'O'), ('.', 'O')], [(\"'CÉIMÍOCHT\", 'O'), (':', 'O'), ('Páistí', 'O'), ('Naíscoil', 'B-ORG'), ('an', 'I-ORG'), ('Lóiste', 'I-ORG'), ('Úir', 'I-ORG'), ('atá', 'O'), ('ag', 'O'), ('dul', 'O'), ('isteach', 'O'), ('i', 'O'), ('rang', 'O'), ('1', 'O'), ('Bunscoil', 'B-ORG'), ('Mhic', 'I-ORG'), ('Reachtain', 'I-ORG'), ('i', 'O'), ('mbliana', 'O'), ('.', 'O')], [('Duine', 'O'), ('fíorthuisceanach', 'O'), ('é', 'O'), ('Ciarán', 'B-PER'), ('a', 'O'), ('thug', 'O'), ('faoi', 'O'), ('deara', 'O'), ('go', 'O'), ('luath', 'O'), ('buanna', 'O'), ('Chaitlín', 'B-PER'), ('Maude', 'I-PER'), ('.', 'O')], [('Ghlac', 'O'), ('aintín', 'O'), ('a', 'O'), ('máthar', 'O'), (',', 'O'), ('Bean', 'O'), ('Uí', 'B-PER'), ('Eidhin', 'I-PER'), (',', 'O'), ('as', 'O'), ('Sráid', 'B-LOC'), ('na', 'I-LOC'), ('Cathrach', 'I-LOC'), (',', 'I-LOC'), ('Co.', 'I-LOC'), ('an', 'I-LOC'), ('Chláir', 'I-LOC'), (',', 'O'), ('cúram', 'O'), ('na', 'O'), ('beirte', 'O'), ('chuici', 'O'), ('féin', 'O'), ('.', 'O')], [('Cuireadh', 'O'), ('tús', 'O'), ('leis', 'O'), ('na', 'O'), ('ranganna', 'O'), ('ag', 'O'), ('Bishopsgate', 'B-ORG'), ('Institute', 'I-ORG'), ('ar', 'O'), ('7', 'O'), ('Deireadh', 'O'), ('Fómhair', 'O'), ('.', 'O')], [('Is', 'O'), ('gnáthach', 'O'), ('leis', 'O'), ('an', 'O'), ('dTaoiseach', 'O'), (',', 'O'), ('Bertie', 'B-PER'), ('Ahern', 'I-PER'), (',', 'O'), ('tamall', 'O'), ('de', 'O'), ('laethanta', 'O'), ('a', 'O'), ('chaitheamh', 'O'), ('san', 'O'), ('óstán', 'O'), ('seo', 'O'), ('gach', 'O'), ('bliain', 'O'), ('agus', 'O'), ('thug', 'O'), ('sé', 'O'), ('cúpla', 'O'), ('lá', 'O'), ('ann', 'O'), ('le', 'O'), ('déanaí', 'O'), ('.', 'O')], [('Bhíodh', 'O'), ('Conall', 'B-PER'), ('Ó', 'I-PER'), ('Dochartaigh', 'I-PER'), ('ag', 'O'), ('airneál', 'O'), ('ag', 'O'), ('an', 'O'), ('mháistir', 'O'), ('go', 'O'), ('mion', 'O'), ('is', 'O'), ('go', 'O'), ('minic', 'O'), ('.', 'O')], [('Chuir', 'O'), ('an', 'O'), ('scéala', 'O'), ('a', 'O'), ('bhí', 'O'), ('ag', 'O'), ('Seosamh', 'B-PER'), ('Ó', 'I-PER'), ('Cearbhaill', 'I-PER'), ('di', 'O'), ('gruaim', 'O'), ('agus', 'O'), ('dubhachas', 'O'), ('uirthi', 'O'), ('.', 'O')]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import tokenizer and create tag dictionary\n",
        "tokenizer = AutoTokenizer.from_pretrained('DCU-NLP/bert-base-irish-cased-v1', do_lower_case=False)\n",
        "\n",
        "tag_values = [\n",
        "        'O',\n",
        "        'B-PER',\n",
        "        'I-PER',\n",
        "        'B-LOC',\n",
        "        'I-LOC',\n",
        "        'B-ORG',\n",
        "        'I-ORG'\n",
        "]\n",
        "\n",
        "tag_values.append(\"PAD\")\n",
        "tag2idx = {t: i for i, t in enumerate(tag_values)}\n"
      ],
      "metadata": {
        "id": "AWr4KZQijflZ"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "n_gpu = torch.cuda.device_count()\n",
        "torch.cuda.get_device_name(0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "qLVRaL3fjzcP",
        "outputId": "3528b9f2-c6cc-49b4-9382-fdfd65bb2e2b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Tesla T4'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the words and labels in the data\n",
        "def splitWordsAndLabels(data_list):\n",
        "  sent = []\n",
        "  labels = []\n",
        "  for lst in data_list:\n",
        "    s = []\n",
        "    l = []\n",
        "    for words in lst:\n",
        "      s.append(words[0])\n",
        "      l.append(words[1])\n",
        "    sent.append(s)\n",
        "    labels.append(l)\n",
        "  return sent, labels\n",
        "\n",
        "train_sent, train_labels = splitWordsAndLabels(train_data)\n",
        "val_sent, val_labels = splitWordsAndLabels(val_data)\n",
        "test_sent, test_labels = splitWordsAndLabels(test_data)\n",
        "mwe_test_sent, mwe_test_labels = splitWordsAndLabels(mwe_test_data)\n",
        "print(train_sent[1])\n",
        "print(train_labels[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WUy78yh2j6--",
        "outputId": "7cbea477-fb3f-4696-a406-9aa209bde39e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Baineann', 'mo', 'cheist', 'le', 'cúrsaí', 'tithíochta', 'i', 'nGaillimh', '-', 'tá', 'sé', 'níos', 'cirte', 'easpa', 'tithíochta', 'i', 'nGaillimh', 'a', 'rá', '-', 'agus', 'an', 'tascfhórsa', 'a', 'bunaíodh', 'breis', 'agus', 'ceithre', 'bliana', 'ó', 'shin']\n",
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize the data and preserve the corresponding labels/tags\n",
        "\n",
        "def tokenize_and_preserve_labels(sentence, text_labels):\n",
        "    tokenized_sentence = []\n",
        "    labels = []\n",
        "\n",
        "    for word, label in zip(sentence, text_labels):\n",
        "        tokenized_word = tokenizer.tokenize(word)\n",
        "        n_subwords = len(tokenized_word)\n",
        "        tokenized_sentence.extend(tokenized_word)\n",
        "        labels.extend([label] * n_subwords)\n",
        "    return tokenized_sentence, labels\n",
        "\n",
        "# Run the splitting function on the training, test, and validation sets\n",
        "tokenized_texts_and_labels = [\n",
        "    tokenize_and_preserve_labels(sent, labs)\n",
        "    for sent, labs in zip(train_sent, train_labels)\n",
        "]\n",
        "\n",
        "val_tokenized_texts_and_labels = [\n",
        "    tokenize_and_preserve_labels(sent, labs)\n",
        "    for sent, labs in zip(val_sent, val_labels)\n",
        "]\n",
        "\n",
        "test_tokenized_texts_and_labels = [\n",
        "    tokenize_and_preserve_labels(sent, labs)\n",
        "    for sent, labs in zip(test_sent, test_labels)\n",
        "]\n",
        "\n",
        "mwe_test_tokenized_texts_and_labels = [\n",
        "    tokenize_and_preserve_labels(sent, labs)\n",
        "    for sent, labs in zip(mwe_test_sent, mwe_test_labels)\n",
        "]\n",
        "\n",
        "# Bring the sentences and labels back together after tokenizing\n",
        "tokenized_texts = [token_label_pair[0] for token_label_pair in tokenized_texts_and_labels]\n",
        "labels = [token_label_pair[1] for token_label_pair in tokenized_texts_and_labels]\n",
        "\n",
        "val_tokenized_texts = [token_label_pair[0] for token_label_pair in val_tokenized_texts_and_labels]\n",
        "val_labels = [token_label_pair[1] for token_label_pair in val_tokenized_texts_and_labels]\n",
        "\n",
        "test_tokenized_texts = [token_label_pair[0] for token_label_pair in test_tokenized_texts_and_labels]\n",
        "test_labels = [token_label_pair[1] for token_label_pair in test_tokenized_texts_and_labels]\n",
        "\n",
        "mwe_test_tokenized_texts = [token_label_pair[0] for token_label_pair in mwe_test_tokenized_texts_and_labels]\n",
        "\n",
        "print(tokenized_texts[1])\n",
        "print(labels[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MNvhL-0Sklzn",
        "outputId": "48a2a1de-fda0-436c-d3a4-a118d1c5669a"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Baineann', 'mo', 'cheist', 'le', 'cúrsaí', 'tithíochta', 'i', 'nGaillimh', '-', 'tá', 'sé', 'níos', 'cirt', '##e', 'easpa', 'tithíochta', 'i', 'nGaillimh', 'a', 'rá', '-', 'agus', 'an', 'tasc', '##fhórsa', 'a', 'bunaíodh', 'breis', 'agus', 'ceithre', 'bliana', 'ó', 'shin']\n",
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the input ids for each dataset\n",
        "input_ids = pad_sequences([tokenizer.convert_tokens_to_ids(txt) for txt in tokenized_texts],\n",
        "                          maxlen=MAX_LEN, dtype=\"long\", value=0.0,\n",
        "                          truncating=\"post\", padding=\"post\")\n",
        "\n",
        "val_input_ids = pad_sequences([tokenizer.convert_tokens_to_ids(txt) for txt in val_tokenized_texts],\n",
        "                          maxlen=MAX_LEN, dtype=\"long\", value=0.0,\n",
        "                          truncating=\"post\", padding=\"post\")\n",
        "\n",
        "test_input_ids = pad_sequences([tokenizer.convert_tokens_to_ids(txt) for txt in test_tokenized_texts],\n",
        "                          maxlen=MAX_LEN, dtype=\"long\", value=0.0,\n",
        "                          truncating=\"post\", padding=\"post\")\n",
        "\n",
        "mwe_test_input_ids = pad_sequences([tokenizer.convert_tokens_to_ids(txt) for txt in mwe_test_tokenized_texts],\n",
        "                          maxlen=MAX_LEN, dtype=\"long\", value=0.0,\n",
        "                          truncating=\"post\", padding=\"post\")\n",
        "\n",
        "# Get the tags for each dataset\n",
        "tags = pad_sequences([[tag2idx.get(l) for l in lab] for lab in labels],\n",
        "                     maxlen=MAX_LEN, value=tag2idx[\"PAD\"], padding=\"post\",\n",
        "                     dtype=\"long\", truncating=\"post\")\n",
        "\n",
        "val_tags = pad_sequences([[tag2idx.get(l) for l in lab] for lab in val_labels],\n",
        "                     maxlen=MAX_LEN, value=tag2idx[\"PAD\"], padding=\"post\",\n",
        "                     dtype=\"long\", truncating=\"post\")\n",
        "\n",
        "test_tags = pad_sequences([[tag2idx.get(l) for l in lab] for lab in test_labels],\n",
        "                     maxlen=MAX_LEN, value=tag2idx[\"PAD\"], padding=\"post\",\n",
        "                     dtype=\"long\", truncating=\"post\")\n",
        "\n",
        "mwe_test_tags = pad_sequences([[tag2idx.get(l) for l in lab] for lab in mwe_test_labels],\n",
        "                     maxlen=MAX_LEN, value=tag2idx[\"PAD\"], padding=\"post\",\n",
        "                     dtype=\"long\", truncating=\"post\")\n",
        "\n",
        "# Create attention masks for each dataset\n",
        "attention_masks = [[float(i != 0.0) for i in ii] for ii in input_ids]\n",
        "\n",
        "val_attention_masks = [[float(i != 0.0) for i in ii] for ii in val_input_ids]\n",
        "\n",
        "test_attention_masks = [[float(i != 0.0) for i in ii] for ii in test_input_ids]\n",
        "\n",
        "mwe_test_attention_masks = [[float(i != 0.0) for i in ii] for ii in mwe_test_input_ids]\n",
        "\n",
        "# Make the inputs, tags, and masks for each dataset into torch tensors\n",
        "tr_inputs = torch.tensor(input_ids)\n",
        "tr_tags = torch.tensor(tags)\n",
        "tr_masks = torch.tensor(attention_masks)\n",
        "\n",
        "vl_inputs = torch.tensor(val_input_ids)\n",
        "vl_tags = torch.tensor(val_tags)\n",
        "vl_masks = torch.tensor(val_attention_masks)\n",
        "\n",
        "tst_inputs = torch.tensor(test_input_ids)\n",
        "tst_tags = torch.tensor(test_tags)\n",
        "tst_masks = torch.tensor(test_attention_masks)\n",
        "\n",
        "mwe_tst_inputs = torch.tensor(mwe_test_input_ids)\n",
        "mwe_tst_tags = torch.tensor(mwe_test_tags)\n",
        "mwe_tst_masks = torch.tensor(mwe_test_attention_masks)\n",
        "\n",
        "# Create a tensor dataset, sampler and dataloader for each dataset\n",
        "tr_data = TensorDataset(tr_inputs, tr_masks, tr_tags)\n",
        "train_sampler = RandomSampler(tr_data) # Sample from the training set randomly\n",
        "train_dataloader = DataLoader(tr_data, sampler=train_sampler, batch_size=bs)\n",
        "\n",
        "valid_data = TensorDataset(vl_inputs, vl_masks, vl_tags)\n",
        "valid_sampler = SequentialSampler(valid_data) # Sample from the validation set sequentially\n",
        "valid_dataloader = DataLoader(valid_data, sampler=valid_sampler, batch_size=bs)\n",
        "\n",
        "tst_data = TensorDataset(tst_inputs, tst_masks, tst_tags)\n",
        "tst_sampler = SequentialSampler(tst_data) # Sample from the test set sequentially\n",
        "tst_dataloader = DataLoader(tst_data, sampler=tst_sampler, batch_size=bs)\n",
        "\n",
        "mwe_tst_data = TensorDataset(mwe_tst_inputs, mwe_tst_masks, mwe_tst_tags)\n",
        "mwe_sampler = SequentialSampler(mwe_tst_data) # Sample from the mwe test set sequentially\n",
        "mwe_tst_dataloader = DataLoader(mwe_tst_data, sampler=mwe_sampler, batch_size=bs)"
      ],
      "metadata": {
        "id": "NWIPnR0blubz"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the model\n",
        "config = BertConfig.from_pretrained('DCU-NLP/bert-base-irish-cased-v1', output_hidden_states=True)\n",
        "config.max_position_embeddings = 512\n",
        "\n",
        "bert_model = BertModel.from_pretrained(\n",
        "                        'DCU-NLP/bert-base-irish-cased-v1',\n",
        "                        config=config,\n",
        "                        add_pooling_layer=False\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "a9c9610bf12f43a5b5e4fc926b29c85c",
            "1c09a6735f0748f994f841eb5c08758d",
            "17cf5a0437964d0a9bb7af6fc7ff2971",
            "63425cf1cc914310acf20578ea5b9d36",
            "182b2b6086404a9ab8bfa517cc27c39f",
            "2885ef1b21e44141bb61d879d1b03aa9",
            "ddb30a69915c47e0b83b980a5dc8e404",
            "ff6f0c71ad8042488aba46eb5be8a3d7",
            "16fe093696d842f4a49a36d44e7efb90",
            "a54614ffad0e4ce0be11c8cf52f0d433",
            "858f408c8baf4c68aa64ddee71d4ab15"
          ]
        },
        "id": "A-foz_SxmFUp",
        "outputId": "fbe94e54-c46c-48d2-cc0f-18a1780b2862"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/439M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a9c9610bf12f43a5b5e4fc926b29c85c"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class BERT_CRF(nn.Module):\n",
        "    def __init__(self, bert_model, num_labels):\n",
        "        super(BERT_CRF, self).__init__()\n",
        "        self.bert = bert_model\n",
        "        self.dropout = nn.Dropout(0.25)\n",
        "        # 4 last of layer\n",
        "        self.classifier = nn.Linear(4*768, num_labels)\n",
        "        self.crf = CRF(num_labels, batch_first = True)\n",
        "\n",
        "    def forward_custom(self, b_input_ids, b_input_mask,  b_labels=None, token_type_ids=None):\n",
        "        outputs = self.bert(b_input_ids, attention_mask=b_input_mask)\n",
        "        sequence_output = torch.cat((outputs[1][-1], outputs[1][-2], outputs[1][-3], outputs[1][-4]),-1)\n",
        "        sequence_output = self.dropout(sequence_output)\n",
        "\n",
        "        emission = self.classifier(sequence_output)\n",
        "\n",
        "        if b_labels is not None:\n",
        "            loss = -self.crf(log_soft(emission, 2), b_labels, mask=b_input_mask.type(torch.uint8), reduction='mean')\n",
        "            prediction = self.crf.decode(emission, mask=b_input_mask.type(torch.uint8))\n",
        "            return [loss, prediction]\n",
        "\n",
        "        else:\n",
        "            prediction = self.crf.decode(emission, mask=b_input_mask.type(torch.uint8))\n",
        "            return prediction"
      ],
      "metadata": {
        "id": "KvfgF5ivnrSM"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = BERT_CRF(bert_model, num_labels=len(tag2idx))\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZ5XghQEnskL",
        "outputId": "e709753b-6d81-4dad-f5d5-de150bf7cd14"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BERT_CRF(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30101, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSdpaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.25, inplace=False)\n",
              "  (classifier): Linear(in_features=3072, out_features=8, bias=True)\n",
              "  (crf): CRF(num_tags=8)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.cuda();"
      ],
      "metadata": {
        "id": "QJBhTS8emIfx"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Optimising parameters for finetuning the model\n",
        "cnt = -1\n",
        "num_layer = 197\n",
        "for param in model.named_parameters():\n",
        "    cnt += 1\n",
        "    if cnt>=num_layer:\n",
        "        param[1].requires_grad = True\n",
        "    else:\n",
        "        param[1].requires_grad = True\n",
        "    print(cnt,param[0],'\\t',param[1].requires_grad)\n",
        "\n",
        "\n",
        "FINETUNING = True\n",
        "if FINETUNING:\n",
        "    param_optimizer1 = list(model.named_parameters())[:num_layer]\n",
        "    param_optimizer2 = list(model.named_parameters())[num_layer:num_layer+2]\n",
        "    param_optimizer3 = list(model.named_parameters())[num_layer+2:]\n",
        "    no_decay = ['bias', 'gamma', 'beta']\n",
        "    optimizer_grouped_parameters = [\n",
        "        {'params': [p for n, p in param_optimizer1 if not any(nd in n for nd in no_decay)],\n",
        "         'weight_decay_rate': 1e-5},\n",
        "        {'params': [p for n, p in param_optimizer1 if any(nd in n for nd in no_decay)],\n",
        "         'weight_decay_rate': 0.0},\n",
        "\n",
        "        {'params': [p for n, p in param_optimizer2 if not any(nd in n for nd in no_decay)],\n",
        "         'weight_decay_rate': 1e-3,\n",
        "         'lr': 1e-3},\n",
        "        {'params': [p for n, p in param_optimizer2 if any(nd in n for nd in no_decay)],\n",
        "         'weight_decay_rate': 0.0,\n",
        "         'lr':1e-3},\n",
        "\n",
        "        {'params': [p for n, p in param_optimizer3 if not any(nd in n for nd in no_decay)],\n",
        "         'weight_decay_rate': 1e-3,\n",
        "         'lr':4e-3},\n",
        "        {'params': [p for n, p in param_optimizer3 if any(nd in n for nd in no_decay)],\n",
        "         'weight_decay_rate': 0.0,\n",
        "         'lr':4e-3}\n",
        "    ]\n",
        "\n",
        "optimizer = AdamW(\n",
        "    optimizer_grouped_parameters,\n",
        "    lr=3e-5,\n",
        "    eps=1e-8\n",
        ")\n",
        "\n",
        "epochs = 10\n",
        "max_grad_norm = 1.0\n",
        "\n",
        "# Total number of training steps = number of batches * number of epochs\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Defining the learning rate scheduler\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps=int(total_steps/10),\n",
        "    num_training_steps=total_steps\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ny7Emj1omJ6Z",
        "outputId": "17987f2d-e267-4033-b2ee-16a7316dc968"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 bert.embeddings.word_embeddings.weight \t True\n",
            "1 bert.embeddings.position_embeddings.weight \t True\n",
            "2 bert.embeddings.token_type_embeddings.weight \t True\n",
            "3 bert.embeddings.LayerNorm.weight \t True\n",
            "4 bert.embeddings.LayerNorm.bias \t True\n",
            "5 bert.encoder.layer.0.attention.self.query.weight \t True\n",
            "6 bert.encoder.layer.0.attention.self.query.bias \t True\n",
            "7 bert.encoder.layer.0.attention.self.key.weight \t True\n",
            "8 bert.encoder.layer.0.attention.self.key.bias \t True\n",
            "9 bert.encoder.layer.0.attention.self.value.weight \t True\n",
            "10 bert.encoder.layer.0.attention.self.value.bias \t True\n",
            "11 bert.encoder.layer.0.attention.output.dense.weight \t True\n",
            "12 bert.encoder.layer.0.attention.output.dense.bias \t True\n",
            "13 bert.encoder.layer.0.attention.output.LayerNorm.weight \t True\n",
            "14 bert.encoder.layer.0.attention.output.LayerNorm.bias \t True\n",
            "15 bert.encoder.layer.0.intermediate.dense.weight \t True\n",
            "16 bert.encoder.layer.0.intermediate.dense.bias \t True\n",
            "17 bert.encoder.layer.0.output.dense.weight \t True\n",
            "18 bert.encoder.layer.0.output.dense.bias \t True\n",
            "19 bert.encoder.layer.0.output.LayerNorm.weight \t True\n",
            "20 bert.encoder.layer.0.output.LayerNorm.bias \t True\n",
            "21 bert.encoder.layer.1.attention.self.query.weight \t True\n",
            "22 bert.encoder.layer.1.attention.self.query.bias \t True\n",
            "23 bert.encoder.layer.1.attention.self.key.weight \t True\n",
            "24 bert.encoder.layer.1.attention.self.key.bias \t True\n",
            "25 bert.encoder.layer.1.attention.self.value.weight \t True\n",
            "26 bert.encoder.layer.1.attention.self.value.bias \t True\n",
            "27 bert.encoder.layer.1.attention.output.dense.weight \t True\n",
            "28 bert.encoder.layer.1.attention.output.dense.bias \t True\n",
            "29 bert.encoder.layer.1.attention.output.LayerNorm.weight \t True\n",
            "30 bert.encoder.layer.1.attention.output.LayerNorm.bias \t True\n",
            "31 bert.encoder.layer.1.intermediate.dense.weight \t True\n",
            "32 bert.encoder.layer.1.intermediate.dense.bias \t True\n",
            "33 bert.encoder.layer.1.output.dense.weight \t True\n",
            "34 bert.encoder.layer.1.output.dense.bias \t True\n",
            "35 bert.encoder.layer.1.output.LayerNorm.weight \t True\n",
            "36 bert.encoder.layer.1.output.LayerNorm.bias \t True\n",
            "37 bert.encoder.layer.2.attention.self.query.weight \t True\n",
            "38 bert.encoder.layer.2.attention.self.query.bias \t True\n",
            "39 bert.encoder.layer.2.attention.self.key.weight \t True\n",
            "40 bert.encoder.layer.2.attention.self.key.bias \t True\n",
            "41 bert.encoder.layer.2.attention.self.value.weight \t True\n",
            "42 bert.encoder.layer.2.attention.self.value.bias \t True\n",
            "43 bert.encoder.layer.2.attention.output.dense.weight \t True\n",
            "44 bert.encoder.layer.2.attention.output.dense.bias \t True\n",
            "45 bert.encoder.layer.2.attention.output.LayerNorm.weight \t True\n",
            "46 bert.encoder.layer.2.attention.output.LayerNorm.bias \t True\n",
            "47 bert.encoder.layer.2.intermediate.dense.weight \t True\n",
            "48 bert.encoder.layer.2.intermediate.dense.bias \t True\n",
            "49 bert.encoder.layer.2.output.dense.weight \t True\n",
            "50 bert.encoder.layer.2.output.dense.bias \t True\n",
            "51 bert.encoder.layer.2.output.LayerNorm.weight \t True\n",
            "52 bert.encoder.layer.2.output.LayerNorm.bias \t True\n",
            "53 bert.encoder.layer.3.attention.self.query.weight \t True\n",
            "54 bert.encoder.layer.3.attention.self.query.bias \t True\n",
            "55 bert.encoder.layer.3.attention.self.key.weight \t True\n",
            "56 bert.encoder.layer.3.attention.self.key.bias \t True\n",
            "57 bert.encoder.layer.3.attention.self.value.weight \t True\n",
            "58 bert.encoder.layer.3.attention.self.value.bias \t True\n",
            "59 bert.encoder.layer.3.attention.output.dense.weight \t True\n",
            "60 bert.encoder.layer.3.attention.output.dense.bias \t True\n",
            "61 bert.encoder.layer.3.attention.output.LayerNorm.weight \t True\n",
            "62 bert.encoder.layer.3.attention.output.LayerNorm.bias \t True\n",
            "63 bert.encoder.layer.3.intermediate.dense.weight \t True\n",
            "64 bert.encoder.layer.3.intermediate.dense.bias \t True\n",
            "65 bert.encoder.layer.3.output.dense.weight \t True\n",
            "66 bert.encoder.layer.3.output.dense.bias \t True\n",
            "67 bert.encoder.layer.3.output.LayerNorm.weight \t True\n",
            "68 bert.encoder.layer.3.output.LayerNorm.bias \t True\n",
            "69 bert.encoder.layer.4.attention.self.query.weight \t True\n",
            "70 bert.encoder.layer.4.attention.self.query.bias \t True\n",
            "71 bert.encoder.layer.4.attention.self.key.weight \t True\n",
            "72 bert.encoder.layer.4.attention.self.key.bias \t True\n",
            "73 bert.encoder.layer.4.attention.self.value.weight \t True\n",
            "74 bert.encoder.layer.4.attention.self.value.bias \t True\n",
            "75 bert.encoder.layer.4.attention.output.dense.weight \t True\n",
            "76 bert.encoder.layer.4.attention.output.dense.bias \t True\n",
            "77 bert.encoder.layer.4.attention.output.LayerNorm.weight \t True\n",
            "78 bert.encoder.layer.4.attention.output.LayerNorm.bias \t True\n",
            "79 bert.encoder.layer.4.intermediate.dense.weight \t True\n",
            "80 bert.encoder.layer.4.intermediate.dense.bias \t True\n",
            "81 bert.encoder.layer.4.output.dense.weight \t True\n",
            "82 bert.encoder.layer.4.output.dense.bias \t True\n",
            "83 bert.encoder.layer.4.output.LayerNorm.weight \t True\n",
            "84 bert.encoder.layer.4.output.LayerNorm.bias \t True\n",
            "85 bert.encoder.layer.5.attention.self.query.weight \t True\n",
            "86 bert.encoder.layer.5.attention.self.query.bias \t True\n",
            "87 bert.encoder.layer.5.attention.self.key.weight \t True\n",
            "88 bert.encoder.layer.5.attention.self.key.bias \t True\n",
            "89 bert.encoder.layer.5.attention.self.value.weight \t True\n",
            "90 bert.encoder.layer.5.attention.self.value.bias \t True\n",
            "91 bert.encoder.layer.5.attention.output.dense.weight \t True\n",
            "92 bert.encoder.layer.5.attention.output.dense.bias \t True\n",
            "93 bert.encoder.layer.5.attention.output.LayerNorm.weight \t True\n",
            "94 bert.encoder.layer.5.attention.output.LayerNorm.bias \t True\n",
            "95 bert.encoder.layer.5.intermediate.dense.weight \t True\n",
            "96 bert.encoder.layer.5.intermediate.dense.bias \t True\n",
            "97 bert.encoder.layer.5.output.dense.weight \t True\n",
            "98 bert.encoder.layer.5.output.dense.bias \t True\n",
            "99 bert.encoder.layer.5.output.LayerNorm.weight \t True\n",
            "100 bert.encoder.layer.5.output.LayerNorm.bias \t True\n",
            "101 bert.encoder.layer.6.attention.self.query.weight \t True\n",
            "102 bert.encoder.layer.6.attention.self.query.bias \t True\n",
            "103 bert.encoder.layer.6.attention.self.key.weight \t True\n",
            "104 bert.encoder.layer.6.attention.self.key.bias \t True\n",
            "105 bert.encoder.layer.6.attention.self.value.weight \t True\n",
            "106 bert.encoder.layer.6.attention.self.value.bias \t True\n",
            "107 bert.encoder.layer.6.attention.output.dense.weight \t True\n",
            "108 bert.encoder.layer.6.attention.output.dense.bias \t True\n",
            "109 bert.encoder.layer.6.attention.output.LayerNorm.weight \t True\n",
            "110 bert.encoder.layer.6.attention.output.LayerNorm.bias \t True\n",
            "111 bert.encoder.layer.6.intermediate.dense.weight \t True\n",
            "112 bert.encoder.layer.6.intermediate.dense.bias \t True\n",
            "113 bert.encoder.layer.6.output.dense.weight \t True\n",
            "114 bert.encoder.layer.6.output.dense.bias \t True\n",
            "115 bert.encoder.layer.6.output.LayerNorm.weight \t True\n",
            "116 bert.encoder.layer.6.output.LayerNorm.bias \t True\n",
            "117 bert.encoder.layer.7.attention.self.query.weight \t True\n",
            "118 bert.encoder.layer.7.attention.self.query.bias \t True\n",
            "119 bert.encoder.layer.7.attention.self.key.weight \t True\n",
            "120 bert.encoder.layer.7.attention.self.key.bias \t True\n",
            "121 bert.encoder.layer.7.attention.self.value.weight \t True\n",
            "122 bert.encoder.layer.7.attention.self.value.bias \t True\n",
            "123 bert.encoder.layer.7.attention.output.dense.weight \t True\n",
            "124 bert.encoder.layer.7.attention.output.dense.bias \t True\n",
            "125 bert.encoder.layer.7.attention.output.LayerNorm.weight \t True\n",
            "126 bert.encoder.layer.7.attention.output.LayerNorm.bias \t True\n",
            "127 bert.encoder.layer.7.intermediate.dense.weight \t True\n",
            "128 bert.encoder.layer.7.intermediate.dense.bias \t True\n",
            "129 bert.encoder.layer.7.output.dense.weight \t True\n",
            "130 bert.encoder.layer.7.output.dense.bias \t True\n",
            "131 bert.encoder.layer.7.output.LayerNorm.weight \t True\n",
            "132 bert.encoder.layer.7.output.LayerNorm.bias \t True\n",
            "133 bert.encoder.layer.8.attention.self.query.weight \t True\n",
            "134 bert.encoder.layer.8.attention.self.query.bias \t True\n",
            "135 bert.encoder.layer.8.attention.self.key.weight \t True\n",
            "136 bert.encoder.layer.8.attention.self.key.bias \t True\n",
            "137 bert.encoder.layer.8.attention.self.value.weight \t True\n",
            "138 bert.encoder.layer.8.attention.self.value.bias \t True\n",
            "139 bert.encoder.layer.8.attention.output.dense.weight \t True\n",
            "140 bert.encoder.layer.8.attention.output.dense.bias \t True\n",
            "141 bert.encoder.layer.8.attention.output.LayerNorm.weight \t True\n",
            "142 bert.encoder.layer.8.attention.output.LayerNorm.bias \t True\n",
            "143 bert.encoder.layer.8.intermediate.dense.weight \t True\n",
            "144 bert.encoder.layer.8.intermediate.dense.bias \t True\n",
            "145 bert.encoder.layer.8.output.dense.weight \t True\n",
            "146 bert.encoder.layer.8.output.dense.bias \t True\n",
            "147 bert.encoder.layer.8.output.LayerNorm.weight \t True\n",
            "148 bert.encoder.layer.8.output.LayerNorm.bias \t True\n",
            "149 bert.encoder.layer.9.attention.self.query.weight \t True\n",
            "150 bert.encoder.layer.9.attention.self.query.bias \t True\n",
            "151 bert.encoder.layer.9.attention.self.key.weight \t True\n",
            "152 bert.encoder.layer.9.attention.self.key.bias \t True\n",
            "153 bert.encoder.layer.9.attention.self.value.weight \t True\n",
            "154 bert.encoder.layer.9.attention.self.value.bias \t True\n",
            "155 bert.encoder.layer.9.attention.output.dense.weight \t True\n",
            "156 bert.encoder.layer.9.attention.output.dense.bias \t True\n",
            "157 bert.encoder.layer.9.attention.output.LayerNorm.weight \t True\n",
            "158 bert.encoder.layer.9.attention.output.LayerNorm.bias \t True\n",
            "159 bert.encoder.layer.9.intermediate.dense.weight \t True\n",
            "160 bert.encoder.layer.9.intermediate.dense.bias \t True\n",
            "161 bert.encoder.layer.9.output.dense.weight \t True\n",
            "162 bert.encoder.layer.9.output.dense.bias \t True\n",
            "163 bert.encoder.layer.9.output.LayerNorm.weight \t True\n",
            "164 bert.encoder.layer.9.output.LayerNorm.bias \t True\n",
            "165 bert.encoder.layer.10.attention.self.query.weight \t True\n",
            "166 bert.encoder.layer.10.attention.self.query.bias \t True\n",
            "167 bert.encoder.layer.10.attention.self.key.weight \t True\n",
            "168 bert.encoder.layer.10.attention.self.key.bias \t True\n",
            "169 bert.encoder.layer.10.attention.self.value.weight \t True\n",
            "170 bert.encoder.layer.10.attention.self.value.bias \t True\n",
            "171 bert.encoder.layer.10.attention.output.dense.weight \t True\n",
            "172 bert.encoder.layer.10.attention.output.dense.bias \t True\n",
            "173 bert.encoder.layer.10.attention.output.LayerNorm.weight \t True\n",
            "174 bert.encoder.layer.10.attention.output.LayerNorm.bias \t True\n",
            "175 bert.encoder.layer.10.intermediate.dense.weight \t True\n",
            "176 bert.encoder.layer.10.intermediate.dense.bias \t True\n",
            "177 bert.encoder.layer.10.output.dense.weight \t True\n",
            "178 bert.encoder.layer.10.output.dense.bias \t True\n",
            "179 bert.encoder.layer.10.output.LayerNorm.weight \t True\n",
            "180 bert.encoder.layer.10.output.LayerNorm.bias \t True\n",
            "181 bert.encoder.layer.11.attention.self.query.weight \t True\n",
            "182 bert.encoder.layer.11.attention.self.query.bias \t True\n",
            "183 bert.encoder.layer.11.attention.self.key.weight \t True\n",
            "184 bert.encoder.layer.11.attention.self.key.bias \t True\n",
            "185 bert.encoder.layer.11.attention.self.value.weight \t True\n",
            "186 bert.encoder.layer.11.attention.self.value.bias \t True\n",
            "187 bert.encoder.layer.11.attention.output.dense.weight \t True\n",
            "188 bert.encoder.layer.11.attention.output.dense.bias \t True\n",
            "189 bert.encoder.layer.11.attention.output.LayerNorm.weight \t True\n",
            "190 bert.encoder.layer.11.attention.output.LayerNorm.bias \t True\n",
            "191 bert.encoder.layer.11.intermediate.dense.weight \t True\n",
            "192 bert.encoder.layer.11.intermediate.dense.bias \t True\n",
            "193 bert.encoder.layer.11.output.dense.weight \t True\n",
            "194 bert.encoder.layer.11.output.dense.bias \t True\n",
            "195 bert.encoder.layer.11.output.LayerNorm.weight \t True\n",
            "196 bert.encoder.layer.11.output.LayerNorm.bias \t True\n",
            "197 classifier.weight \t True\n",
            "198 classifier.bias \t True\n",
            "199 crf.start_transitions \t True\n",
            "200 crf.end_transitions \t True\n",
            "201 crf.transitions \t True\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Store the average loss after each epoch so we can plot them\n",
        "loss_values, validation_loss_values = [], []\n",
        "best_model_state = None\n",
        "patience = 2\n",
        "best_val_loss = float('inf')\n",
        "epochs_without_improvement = 0\n",
        "best_epoch = 0\n",
        "\n",
        "for epoch in trange(epochs, desc=\"Epoch\"):\n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    # Perform one full pass over the training set\n",
        "\n",
        "    # Put the model into training mode\n",
        "    model.train()\n",
        "    # Reset the total loss for this epoch\n",
        "    total_loss = 0\n",
        "\n",
        "    # Training loop\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        # add batch to gpu\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        # Always clear any previously calculated gradients before performing a backward pass\n",
        "        model.zero_grad()\n",
        "        # forward pass\n",
        "        # This will return the loss (rather than the model output)\n",
        "        # because we have provided the `labels`\n",
        "        outputs = model.forward_custom(b_input_ids, b_input_mask, b_labels, token_type_ids=None)\n",
        "        # get the loss\n",
        "        loss = outputs[0]\n",
        "        # Perform a backward pass to calculate the gradients\n",
        "        loss.backward()\n",
        "        # track train loss\n",
        "        total_loss += loss.item()\n",
        "        # Clip the norm of the gradient\n",
        "        # This is to help prevent the \"exploding gradients\" problem\n",
        "        torch.nn.utils.clip_grad_norm_(parameters=model.parameters(), max_norm=max_grad_norm)\n",
        "        # update parameters\n",
        "        optimizer.step()\n",
        "        # Update the learning rate\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over the training data\n",
        "    avg_train_loss = total_loss / len(train_dataloader)\n",
        "    print(\"Average train loss: {}\".format(avg_train_loss))\n",
        "\n",
        "    # Store the loss value for plotting the learning curve\n",
        "    loss_values.append(avg_train_loss)\n",
        "\n",
        "\n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set\n",
        "\n",
        "    # Put the model into evaluation mode\n",
        "    model.eval()\n",
        "    # Reset the validation loss for this epoch\n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "    predictions , true_labels = [], []\n",
        "    for batch in valid_dataloader:\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "        # Telling the model not to compute or store gradients,\n",
        "        # saving memory and speeding up validation\n",
        "        with torch.no_grad():\n",
        "            # Forward pass, calculate logit predictions\n",
        "            # This will return the logits rather than the loss because we have not provided labels\n",
        "            outputs = model.forward_custom(b_input_ids, b_input_mask, b_labels, token_type_ids=None)\n",
        "        # Move logits and labels to CPU\n",
        "        logits = outputs[0].detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Calculate the accuracy for this batch of test sentences\n",
        "        eval_loss += outputs[0].mean().item()\n",
        "        predictions.extend(outputs[1])\n",
        "        true_labels.extend(label_ids)\n",
        "\n",
        "    eval_loss = eval_loss / len(valid_dataloader)\n",
        "    validation_loss_values.append(eval_loss)\n",
        "    print(\"Validation loss: {}\".format(eval_loss))\n",
        "    pred_tags = []\n",
        "    valid_tags = []\n",
        "    for p, l in zip(predictions, true_labels):\n",
        "        for p_i, l_i in zip(p, l):\n",
        "            if tag_values[l_i] != \"PAD\":\n",
        "                pred_tags.append(tag_values[p_i])\n",
        "                valid_tags.append(tag_values[l_i])\n",
        "                tokens = tokenizer.convert_ids_to_tokens(b_input_ids[0].to('cpu').numpy())\n",
        "                new_tokens, new_labels, new_preds = [], [], []\n",
        "                for token, label_idx, pred in zip(tokens, l, p):\n",
        "                    if token.startswith(\"##\"):\n",
        "                        new_tokens[-1] = new_tokens[-1] + token[2:]\n",
        "                    else:\n",
        "                        new_labels.append(label_idx)\n",
        "                        new_preds.append(pred)\n",
        "                        new_tokens.append(token)\n",
        "                for token, pred, label in zip(new_tokens, new_preds, new_labels):\n",
        "                    pred_tags.append(tag_values[pred])\n",
        "                    valid_tags.append(tag_values[label])\n",
        "\n",
        "    print(\"Validation Accuracy: {}\".format(accuracy_score(pred_tags, valid_tags)))\n",
        "    val_report = classification_report(valid_tags, pred_tags)\n",
        "    print(\"Epoch {} - Validation Classification Report:\".format(epoch))\n",
        "    print(val_report)\n",
        "    if eval_loss < best_val_loss:\n",
        "      best_val_loss = eval_loss\n",
        "      best_epoch = epoch\n",
        "      best_model_state = model.state_dict()\n",
        "      epochs_without_improvement = 0\n",
        "    else:\n",
        "      epochs_without_improvement += 1\n",
        "      if epochs_without_improvement >= patience:\n",
        "          print(f\"Validation loss hasn't improved for {patience} epochs. Best model found at epoch {best_epoch}.\")\n",
        "          break\n",
        "\n",
        "    print(\"Epoch {} - Training Loss: {:.4f}, Validation Loss: {:.4f}\".format(epoch, avg_train_loss, eval_loss))\n",
        "    print()\n",
        "\n",
        "# Output the best epoch model\n",
        "if best_model_state is not None:\n",
        "    torch.save(best_model_state, \"gaBERT_CRF.pt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KPa5gEWDmatX",
        "outputId": "a75237f9-77a7-4cef-c857-9c8dfb788d07"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:   0%|          | 0/10 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average train loss: 3.1891976706683636\n",
            "Validation loss: 6.143548607826233\n",
            "Validation Accuracy: 0.9441918716608511\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  10%|█         | 1/10 [00:55<08:16, 55.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 - Validation Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       B-LOC       0.95      0.85      0.90      2563\n",
            "       B-ORG       0.64      0.89      0.74      4166\n",
            "       B-PER       0.84      0.70      0.76      3450\n",
            "       I-LOC       0.76      0.98      0.86      1681\n",
            "       I-ORG       0.61      0.76      0.68      4941\n",
            "       I-PER       0.80      0.74      0.77      6028\n",
            "           O       0.99      0.97      0.98    115305\n",
            "\n",
            "    accuracy                           0.94    138134\n",
            "   macro avg       0.80      0.84      0.81    138134\n",
            "weighted avg       0.95      0.94      0.95    138134\n",
            "\n",
            "Epoch 0 - Training Loss: 3.1892, Validation Loss: 6.1435\n",
            "\n",
            "Average train loss: 1.6048012245446444\n",
            "Validation loss: 5.887268424034119\n",
            "Validation Accuracy: 0.9437357927809229\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  20%|██        | 2/10 [01:50<07:22, 55.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 - Validation Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       B-LOC       0.95      0.84      0.89      2563\n",
            "       B-ORG       0.70      0.80      0.74      4166\n",
            "       B-PER       0.68      0.72      0.70      3450\n",
            "       I-LOC       0.83      0.97      0.89      1681\n",
            "       I-ORG       0.61      0.82      0.70      4941\n",
            "       I-PER       0.83      0.74      0.78      6028\n",
            "           O       0.99      0.97      0.98    115305\n",
            "\n",
            "    accuracy                           0.94    138134\n",
            "   macro avg       0.80      0.84      0.81    138134\n",
            "weighted avg       0.95      0.94      0.95    138134\n",
            "\n",
            "Epoch 1 - Training Loss: 1.6048, Validation Loss: 5.8873\n",
            "\n",
            "Average train loss: 0.8547236500307918\n",
            "Validation loss: 6.464193105697632\n",
            "Validation Accuracy: 0.9479997683408864\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  30%|███       | 3/10 [02:43<06:20, 54.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 - Validation Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       B-LOC       0.95      0.88      0.92      2563\n",
            "       B-ORG       0.70      0.82      0.75      4166\n",
            "       B-PER       0.87      0.70      0.78      3450\n",
            "       I-LOC       0.77      0.97      0.86      1681\n",
            "       I-ORG       0.62      0.84      0.71      4941\n",
            "       I-PER       0.83      0.72      0.77      6028\n",
            "           O       0.99      0.98      0.98    115305\n",
            "\n",
            "    accuracy                           0.95    138134\n",
            "   macro avg       0.82      0.84      0.82    138134\n",
            "weighted avg       0.95      0.95      0.95    138134\n",
            "\n",
            "Epoch 2 - Training Loss: 0.8547, Validation Loss: 6.4642\n",
            "\n",
            "Average train loss: 0.49878982035443187\n",
            "Validation loss: 6.735937714576721\n",
            "Validation Accuracy: 0.9478622207421779\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  30%|███       | 3/10 [03:39<08:31, 73.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 - Validation Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       B-LOC       0.95      0.88      0.92      2563\n",
            "       B-ORG       0.75      0.75      0.75      4166\n",
            "       B-PER       0.85      0.71      0.78      3450\n",
            "       I-LOC       0.81      0.97      0.88      1681\n",
            "       I-ORG       0.59      0.81      0.68      4941\n",
            "       I-PER       0.82      0.73      0.77      6028\n",
            "           O       0.99      0.98      0.98    115305\n",
            "\n",
            "    accuracy                           0.95    138134\n",
            "   macro avg       0.82      0.83      0.82    138134\n",
            "weighted avg       0.95      0.95      0.95    138134\n",
            "\n",
            "Validation loss hasn't improved for 2 epochs. Best model found at epoch 1.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best model saved to 'final_gabert_V1_5.pt'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training and Validation Loss Plot\n",
        "\n",
        "# Generate x-axis values (epochs)\n",
        "epochs = range(len(loss_values) + 1)\n",
        "\n",
        "# Plotting with markers and lines\n",
        "plt.plot(epochs[:-1], loss_values, marker='o', linestyle='-', label='Training Loss', color='blue')\n",
        "plt.plot(epochs[:-1], validation_loss_values, marker='o', linestyle='-', label='Validation Loss', color='orange')\n",
        "\n",
        "# Labeling and styling\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "# Set ticks for x-axis (epochs) to whole numbers only starting from 0\n",
        "plt.xticks(epochs[:-1])\n",
        "\n",
        "\n",
        "# Ensure y-axis (loss) ticks are whole numbers only\n",
        "#plt.yticks(range(int(min(min(loss_values), min(validation_loss_values))), int(max(max(loss_values), max(validation_loss_values))) + 1))\n",
        "plt.savefig('gabert_CRF_training_validation_loss_plot.png')\n",
        "# Show plot\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "C4eXQCgcm28q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "outputId": "daba7827-d2be-4c37-e832-674176060c6e"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "\n",
        "predicted_labels = []\n",
        "true_labels = []\n",
        "\n",
        "# Iterate through the test_dataloader to get the predictions\n",
        "# Using the GPU\n",
        "for batch in tst_dataloader:\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    inputs = {'input_ids': batch[0], 'attention_mask': batch[1], 'labels': batch[2]}\n",
        "\n",
        "    # Disabling gradient calculation for evaluation\n",
        "    with torch.no_grad():\n",
        "        #outputs = model(**inputs)\n",
        "        outputs = model.forward_custom(batch[0], batch[1], batch[2], token_type_ids=None)\n",
        "\n",
        "    # Extracting the predictions and also the true labels for the test data\n",
        "    predict_labels = outputs[1]\n",
        "    #print(predict_labels)\n",
        "    predictions = []\n",
        "    for predict_label in predict_labels:\n",
        "      #print(predict_label)\n",
        "      predicted_labels.append(predict_label)\n",
        "    #predicted_labels.append(predictions)\n",
        "\n",
        "    true_labels.extend(inputs['labels'].tolist())"
      ],
      "metadata": {
        "id": "3P57y4KgnJkB"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trues = []\n",
        "\n",
        "for sentences in true_labels:\n",
        "  t = []\n",
        "  for vals in sentences:\n",
        "    if vals != 7:\n",
        "      t.append(vals)\n",
        "  trues.append(t)\n",
        "\n",
        "preds=predicted_labels"
      ],
      "metadata": {
        "id": "Lp6AgFI02agf"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "i = 0\n",
        "while i < len(preds):\n",
        "  if len(test_labels[i]) != len(preds[i]):\n",
        "    print(f'issue: {i} {len(test_labels[i])}, {len(preds[i])}')\n",
        "    print(f'{test_tokenized_texts[i]}\\n{test_labels[i]}\\n{preds[i]}')\n",
        "    i += 1\n",
        "  i += 1"
      ],
      "metadata": {
        "id": "5lRDVwGr2hr2"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_map = {\n",
        "    0: 'O',\n",
        "    1: 'B-PER',\n",
        "    2: 'I-PER',\n",
        "    3: 'B-LOC',\n",
        "    4: 'I-LOC',\n",
        "    5: 'B-ORG',\n",
        "    6: 'I-ORG'\n",
        "}\n",
        "\n",
        "# Initialise an empty list to store DataFrames\n",
        "dfs = []\n",
        "\n",
        "# Iterate through the tokens, labels, and predictions\n",
        "for tokens, labels, predictions in zip(test_tokenized_texts, test_labels, preds):\n",
        "    # Create a DataFrame from the current sublist\n",
        "    temp_df = pd.DataFrame({'Word': tokens, 'POS': 'X', 'True': labels, 'Predicted': [label_map[pred] for pred in predictions]})\n",
        "    # Append the DataFrame to the list\n",
        "    dfs.append(temp_df)\n",
        "    # Add an empty row as a DataFrame to the list\n",
        "    dfs.append(pd.DataFrame({'Word': [''], 'POS': [''], 'True': [''], 'Predicted': ['']}))\n",
        "\n",
        "# Concatenate the DataFrames along the rows axis\n",
        "df = pd.concat(dfs, ignore_index=True)\n",
        "\n",
        "# Print the concatenated DataFrame\n",
        "print(df)\n",
        "\n",
        "# Check the alignment is correct\n",
        "print(df.head(45))"
      ],
      "metadata": {
        "id": "LZwh74eInh4z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59eaf2aa-5792-4432-8731-2f53882ac014"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           Word POS   True Predicted\n",
            "0           Mar   X      O         O\n",
            "1             a   X      O         O\n",
            "2             t   X      O         O\n",
            "3          ##ch   X      O         O\n",
            "4       ##ítear   X      O         O\n",
            "...         ...  ..    ...       ...\n",
            "4839          a   X      O         O\n",
            "4840     bhfuil   X      O         O\n",
            "4841  Gaeltacht   X  B-LOC     B-LOC\n",
            "4842        ann   X      O         O\n",
            "4843                                \n",
            "\n",
            "[4844 rows x 4 columns]\n",
            "           Word POS   True Predicted\n",
            "0           Mar   X      O         O\n",
            "1             a   X      O         O\n",
            "2             t   X      O         O\n",
            "3          ##ch   X      O         O\n",
            "4       ##ítear   X      O         O\n",
            "5            do   X      O         O\n",
            "6         Sheos   X  B-PER     B-PER\n",
            "7         ##amh   X  B-PER     B-PER\n",
            "8           Mac   X  I-PER     I-PER\n",
            "9       Grianna   X  I-PER     I-PER\n",
            "10            é   X      O         O\n",
            "11    caithfidh   X      O         O\n",
            "12           an   X      O         O\n",
            "13            t   X      O         O\n",
            "14            -   X      O         O\n",
            "15  ealaíontóir   X      O         O\n",
            "16           an   X      O         O\n",
            "17        solas   X      O         O\n",
            "18            a   X      O         O\n",
            "19    thabhairt   X      O         O\n",
            "20          don   X      O         O\n",
            "21         saol   X      O         O\n",
            "22         agus   X      O         O\n",
            "23       diúltú   X      O         O\n",
            "24           do   X      O         O\n",
            "25        chath   X      O         O\n",
            "26          ##ú   X      O         O\n",
            "27          sin   X      O         O\n",
            "28           na   X      O         O\n",
            "29      truaill   X      O         O\n",
            "30     ##íochta   X      O         O\n",
            "31            a   X      O         O\n",
            "32    chuireann   X      O         O\n",
            "33           an   X      O         O\n",
            "34         saol   X      O         O\n",
            "35          ina   X      O         O\n",
            "36         chos   X      O         O\n",
            "37         ##án   X      O         O\n",
            "38            .   X      O         O\n",
            "39                                  \n",
            "40   Dhiúltaigh   X      O         O\n",
            "41         John   X  B-PER     B-PER\n",
            "42       ##atha   X  B-PER     B-PER\n",
            "43          ##n   X  B-PER     B-PER\n",
            "44         Cape   X  I-PER     I-PER\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Change to conll format for evaluation script to be run\n",
        "conll_format = \"\"\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "    text = row['Word']\n",
        "    pos = row['POS']\n",
        "    tag = row['True']\n",
        "    mapped_tag = row['Predicted']\n",
        "\n",
        "    # Append the token in CoNLL format (word, POS, gold_label, predicted_label)\n",
        "    conll_format += f\"{text}\\t{pos}\\t{tag}\\t{mapped_tag}\\n\"\n",
        "\n",
        "# Write the CoNLL format string to a text file\n",
        "with open('gaBERT_CRF.conll', 'w') as f:\n",
        "    f.write(conll_format)"
      ],
      "metadata": {
        "id": "5xWSYW9Pnqjw"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#MWE case study"
      ],
      "metadata": {
        "id": "u1ojsiBYumYY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "\n",
        "mwe_predicted_labels = []\n",
        "mwe_true_labels = []\n",
        "\n",
        "# Iterate through the test_dataloader to get the predictions\n",
        "# Using the GPU\n",
        "for batch in mwe_tst_dataloader:\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    inputs = {'input_ids': batch[0], 'attention_mask': batch[1], 'labels': batch[2]}\n",
        "\n",
        "    # Disabling gradient calculation for evaluation\n",
        "    with torch.no_grad():\n",
        "        #outputs = model(**inputs)\n",
        "        outputs = model.forward_custom(batch[0], batch[1], batch[2], token_type_ids=None)\n",
        "\n",
        "    # Extracting the predictions and also the true labels for the test data\n",
        "    predict_labels = outputs[1]\n",
        "    #print(predict_labels)\n",
        "    predictions = []\n",
        "    for predict_label in predict_labels:\n",
        "      #print(predict_label)\n",
        "      mwe_predicted_labels.append(predict_label)\n",
        "    #predicted_labels.append(predictions)\n",
        "\n",
        "    mwe_true_labels.extend(inputs['labels'].tolist())"
      ],
      "metadata": {
        "id": "B9_05h4m2tnI"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#print(mwe_predicted_labels)"
      ],
      "metadata": {
        "id": "_yLRcpsp4jSJ"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(mwe_predicted_labels))\n",
        "print(len(mwe_true_labels))"
      ],
      "metadata": {
        "id": "ia306Uia40Im",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c53c64f-bcad-485b-f076-14eedd309ad2"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "89\n",
            "89\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(mwe_true_labels[0])\n",
        "print(mwe_predicted_labels[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yi7pcVbr4LqG",
        "outputId": "aa08795a-9133-4e1b-a83a-fad581eec52c"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7]\n",
            "[0, 0, 0, 0, 0, 0, 1, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mwe_preds = []\n",
        "mwe_trues = []\n",
        "\n",
        "for sentences in mwe_true_labels:\n",
        "  t = []\n",
        "  for vals in sentences:\n",
        "    if vals != 7:\n",
        "      t.append(vals)\n",
        "  mwe_trues.append(t)\n",
        "\n",
        "for sentences in mwe_predicted_labels:\n",
        "  p = []\n",
        "  for vals in sentences:\n",
        "    if vals != 7:\n",
        "      p.append(vals)\n",
        "  mwe_preds.append(p)\n",
        "\n",
        "\n",
        "#print(mwe_test_tokenized_texts_and_labels)\n",
        "mwe_tokenized_labels = []\n",
        "for sentence, labels in mwe_test_tokenized_texts_and_labels:\n",
        "    mwe_tokenized_labels.append(labels)\n",
        "\n",
        "print(len(mwe_test_tokenized_texts[0]))\n",
        "print(len(mwe_trues[0]))\n",
        "print(len(mwe_tokenized_labels[0]))\n",
        "print(len(mwe_preds[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cPqaCWM84TA9",
        "outputId": "a747c1ea-eace-4c10-a5f3-dc52b10b507d"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "39\n",
            "31\n",
            "39\n",
            "39\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "i = 0\n",
        "while i < len(mwe_tokenized_labels):\n",
        "  #print(len(mwe_true_labels[i]))\n",
        "  #print(len(mwe_predicted_labels[i]))\n",
        "  #print(i)\n",
        "  if len(mwe_tokenized_labels[i]) != len(mwe_preds[i]):\n",
        "    print('issue')\n",
        "    i += 1\n",
        "  i += 1"
      ],
      "metadata": {
        "id": "x2E_S6pe3Dp1"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialise an empty list to store DataFrames\n",
        "dfs = []\n",
        "\n",
        "# Iterate through the tokens, labels, and predictions\n",
        "for tokens, labels, predictions in zip(mwe_test_tokenized_texts, mwe_tokenized_labels, mwe_preds):\n",
        "    # Create a DataFrame from the current sublist\n",
        "    temp_df = pd.DataFrame({'Word': tokens, 'POS': 'X', 'True': labels, 'Predicted': [label_map[pred] for pred in predictions]})\n",
        "    # Append the DataFrame to the list\n",
        "    dfs.append(temp_df)\n",
        "    # Add an empty row as a DataFrame to the list\n",
        "    dfs.append(pd.DataFrame({'Word': [''], 'POS': [''], 'True': [''], 'Predicted': ['']}))\n",
        "\n",
        "# Concatenate the DataFrames along the rows axis\n",
        "df = pd.concat(dfs, ignore_index=True)\n",
        "\n",
        "# Print the concatenated DataFrame\n",
        "print(df)\n",
        "\n",
        "# Check the alignment is correct\n",
        "print(df.head(45))"
      ],
      "metadata": {
        "id": "O5wTG1Gf8UEx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03366e21-89b6-4fc0-ffa7-c690b6958fe9"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         Word POS   True Predicted\n",
            "0         Mar   X      O         O\n",
            "1           a   X      O         O\n",
            "2           t   X      O         O\n",
            "3        ##ch   X      O         O\n",
            "4     ##ítear   X      O         O\n",
            "...       ...  ..    ...       ...\n",
            "3167       na   X  I-LOC     I-LOC\n",
            "3168       nD   X  I-LOC     I-LOC\n",
            "3169   ##éise   X  I-LOC     I-LOC\n",
            "3170        .   X      O         O\n",
            "3171                              \n",
            "\n",
            "[3172 rows x 4 columns]\n",
            "           Word POS   True Predicted\n",
            "0           Mar   X      O         O\n",
            "1             a   X      O         O\n",
            "2             t   X      O         O\n",
            "3          ##ch   X      O         O\n",
            "4       ##ítear   X      O         O\n",
            "5            do   X      O         O\n",
            "6         Sheos   X  B-PER     B-PER\n",
            "7         ##amh   X  B-PER     B-PER\n",
            "8           Mac   X  I-PER     I-PER\n",
            "9       Grianna   X  I-PER     I-PER\n",
            "10            é   X      O         O\n",
            "11    caithfidh   X      O         O\n",
            "12           an   X      O         O\n",
            "13            t   X      O         O\n",
            "14            -   X      O         O\n",
            "15  ealaíontóir   X      O         O\n",
            "16           an   X      O         O\n",
            "17        solas   X      O         O\n",
            "18            a   X      O         O\n",
            "19    thabhairt   X      O         O\n",
            "20          don   X      O         O\n",
            "21         saol   X      O         O\n",
            "22         agus   X      O         O\n",
            "23       diúltú   X      O         O\n",
            "24           do   X      O         O\n",
            "25        chath   X      O         O\n",
            "26          ##ú   X      O         O\n",
            "27          sin   X      O         O\n",
            "28           na   X      O         O\n",
            "29      truaill   X      O         O\n",
            "30     ##íochta   X      O         O\n",
            "31            a   X      O         O\n",
            "32    chuireann   X      O         O\n",
            "33           an   X      O         O\n",
            "34         saol   X      O         O\n",
            "35          ina   X      O         O\n",
            "36         chos   X      O         O\n",
            "37         ##án   X      O         O\n",
            "38            .   X      O         O\n",
            "39                                  \n",
            "40  Grianghraif   X      O         O\n",
            "41           le   X      O         O\n",
            "42       Maidhc   X  B-PER     B-PER\n",
            "43            Ó   X  I-PER     I-PER\n",
            "44        Seach   X  I-PER     I-PER\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Change to conll format for evaluation script to be run\n",
        "conll_format = \"\"\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "    text = row['Word']\n",
        "    pos = row['POS']\n",
        "    tag = row['True']\n",
        "    mapped_tag = row['Predicted']\n",
        "\n",
        "    # Append the token in CoNLL format (word, POS, gold_label, predicted_label)\n",
        "    conll_format += f\"{text}\\t{pos}\\t{tag}\\t{mapped_tag}\\n\"\n",
        "\n",
        "# Write the CoNLL format string to a text file\n",
        "with open('gaBERT_CRF_MWE.conll', 'w') as f:\n",
        "    f.write(conll_format)"
      ],
      "metadata": {
        "id": "_blFxH196M2J"
      },
      "execution_count": 85,
      "outputs": []
    }
  ]
}